{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Following is to load spark module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze airline data with Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Analyze airline data\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import Row\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Loading in airline data, for detailed explanation see pluralsight. ####### Spark2 by Janani Ravi. This has been modified  and is not exactly as in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlinesPath = \"datasets/airlines.csv\"\n",
    "flightsPath = \"datasets/flights.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\padma\\spark\\spark-sql\\tools\\spark-3.1.2-bin-hadoop2.7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ.get('SPARK_HOME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install pandas\n",
    "# format date\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"Date\": [\"26-12-2007\", \"27-12-2007\", \"28-12-2007\"]})\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"]).dt.strftime('%Y-%m-%d')\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date\n",
      "0  2007-12-26\n",
      "1  2007-12-27\n",
      "2  2007-12-28\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark DataFrame\n",
    "flights = spark.read\\\n",
    "                .format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .load(flightsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert spark dataframe to pandas dataframe. Note that the pandas and spark dataframe are not the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_d31f1_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >date</th>        <th class=\"col_heading level0 col1\" >airlines</th>        <th class=\"col_heading level0 col2\" >flight_number</th>        <th class=\"col_heading level0 col3\" >origin</th>        <th class=\"col_heading level0 col4\" >destination</th>        <th class=\"col_heading level0 col5\" >departure</th>        <th class=\"col_heading level0 col6\" >departure_delay</th>        <th class=\"col_heading level0 col7\" >arrival</th>        <th class=\"col_heading level0 col8\" >arrival_delay</th>        <th class=\"col_heading level0 col9\" >air_time</th>        <th class=\"col_heading level0 col10\" >distance</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_d31f1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_d31f1_row0_col0\" class=\"data row0 col0\" >2014-04-01</td>\n",
       "                        <td id=\"T_d31f1_row0_col1\" class=\"data row0 col1\" >19805</td>\n",
       "                        <td id=\"T_d31f1_row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "                        <td id=\"T_d31f1_row0_col3\" class=\"data row0 col3\" >JFK</td>\n",
       "                        <td id=\"T_d31f1_row0_col4\" class=\"data row0 col4\" >LAX</td>\n",
       "                        <td id=\"T_d31f1_row0_col5\" class=\"data row0 col5\" >0854</td>\n",
       "                        <td id=\"T_d31f1_row0_col6\" class=\"data row0 col6\" >-6.00</td>\n",
       "                        <td id=\"T_d31f1_row0_col7\" class=\"data row0 col7\" >1217</td>\n",
       "                        <td id=\"T_d31f1_row0_col8\" class=\"data row0 col8\" >2.00</td>\n",
       "                        <td id=\"T_d31f1_row0_col9\" class=\"data row0 col9\" >355.00</td>\n",
       "                        <td id=\"T_d31f1_row0_col10\" class=\"data row0 col10\" >2475.00</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d31f1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_d31f1_row1_col0\" class=\"data row1 col0\" >2014-04-01</td>\n",
       "                        <td id=\"T_d31f1_row1_col1\" class=\"data row1 col1\" >19805</td>\n",
       "                        <td id=\"T_d31f1_row1_col2\" class=\"data row1 col2\" >2</td>\n",
       "                        <td id=\"T_d31f1_row1_col3\" class=\"data row1 col3\" >LAX</td>\n",
       "                        <td id=\"T_d31f1_row1_col4\" class=\"data row1 col4\" >JFK</td>\n",
       "                        <td id=\"T_d31f1_row1_col5\" class=\"data row1 col5\" >0944</td>\n",
       "                        <td id=\"T_d31f1_row1_col6\" class=\"data row1 col6\" >14.00</td>\n",
       "                        <td id=\"T_d31f1_row1_col7\" class=\"data row1 col7\" >1736</td>\n",
       "                        <td id=\"T_d31f1_row1_col8\" class=\"data row1 col8\" >-29.00</td>\n",
       "                        <td id=\"T_d31f1_row1_col9\" class=\"data row1 col9\" >269.00</td>\n",
       "                        <td id=\"T_d31f1_row1_col10\" class=\"data row1 col10\" >2475.00</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d31f1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_d31f1_row2_col0\" class=\"data row2 col0\" >2014-04-01</td>\n",
       "                        <td id=\"T_d31f1_row2_col1\" class=\"data row2 col1\" >19805</td>\n",
       "                        <td id=\"T_d31f1_row2_col2\" class=\"data row2 col2\" >3</td>\n",
       "                        <td id=\"T_d31f1_row2_col3\" class=\"data row2 col3\" >JFK</td>\n",
       "                        <td id=\"T_d31f1_row2_col4\" class=\"data row2 col4\" >LAX</td>\n",
       "                        <td id=\"T_d31f1_row2_col5\" class=\"data row2 col5\" >1224</td>\n",
       "                        <td id=\"T_d31f1_row2_col6\" class=\"data row2 col6\" >-6.00</td>\n",
       "                        <td id=\"T_d31f1_row2_col7\" class=\"data row2 col7\" >1614</td>\n",
       "                        <td id=\"T_d31f1_row2_col8\" class=\"data row2 col8\" >39.00</td>\n",
       "                        <td id=\"T_d31f1_row2_col9\" class=\"data row2 col9\" >371.00</td>\n",
       "                        <td id=\"T_d31f1_row2_col10\" class=\"data row2 col10\" >2475.00</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d31f1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_d31f1_row3_col0\" class=\"data row3 col0\" >2014-04-01</td>\n",
       "                        <td id=\"T_d31f1_row3_col1\" class=\"data row3 col1\" >19805</td>\n",
       "                        <td id=\"T_d31f1_row3_col2\" class=\"data row3 col2\" >4</td>\n",
       "                        <td id=\"T_d31f1_row3_col3\" class=\"data row3 col3\" >LAX</td>\n",
       "                        <td id=\"T_d31f1_row3_col4\" class=\"data row3 col4\" >JFK</td>\n",
       "                        <td id=\"T_d31f1_row3_col5\" class=\"data row3 col5\" >1240</td>\n",
       "                        <td id=\"T_d31f1_row3_col6\" class=\"data row3 col6\" >25.00</td>\n",
       "                        <td id=\"T_d31f1_row3_col7\" class=\"data row3 col7\" >2028</td>\n",
       "                        <td id=\"T_d31f1_row3_col8\" class=\"data row3 col8\" >-27.00</td>\n",
       "                        <td id=\"T_d31f1_row3_col9\" class=\"data row3 col9\" >264.00</td>\n",
       "                        <td id=\"T_d31f1_row3_col10\" class=\"data row3 col10\" >2475.00</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d31f1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_d31f1_row4_col0\" class=\"data row4 col0\" >2014-04-01</td>\n",
       "                        <td id=\"T_d31f1_row4_col1\" class=\"data row4 col1\" >19805</td>\n",
       "                        <td id=\"T_d31f1_row4_col2\" class=\"data row4 col2\" >5</td>\n",
       "                        <td id=\"T_d31f1_row4_col3\" class=\"data row4 col3\" >DFW</td>\n",
       "                        <td id=\"T_d31f1_row4_col4\" class=\"data row4 col4\" >HNL</td>\n",
       "                        <td id=\"T_d31f1_row4_col5\" class=\"data row4 col5\" >1300</td>\n",
       "                        <td id=\"T_d31f1_row4_col6\" class=\"data row4 col6\" >-5.00</td>\n",
       "                        <td id=\"T_d31f1_row4_col7\" class=\"data row4 col7\" >1650</td>\n",
       "                        <td id=\"T_d31f1_row4_col8\" class=\"data row4 col8\" >15.00</td>\n",
       "                        <td id=\"T_d31f1_row4_col9\" class=\"data row4 col9\" >510.00</td>\n",
       "                        <td id=\"T_d31f1_row4_col10\" class=\"data row4 col10\" >3784.00</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d31f1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_d31f1_row5_col0\" class=\"data row5 col0\" >2014-04-01</td>\n",
       "                        <td id=\"T_d31f1_row5_col1\" class=\"data row5 col1\" >19805</td>\n",
       "                        <td id=\"T_d31f1_row5_col2\" class=\"data row5 col2\" >6</td>\n",
       "                        <td id=\"T_d31f1_row5_col3\" class=\"data row5 col3\" >OGG</td>\n",
       "                        <td id=\"T_d31f1_row5_col4\" class=\"data row5 col4\" >DFW</td>\n",
       "                        <td id=\"T_d31f1_row5_col5\" class=\"data row5 col5\" >1901</td>\n",
       "                        <td id=\"T_d31f1_row5_col6\" class=\"data row5 col6\" >126.00</td>\n",
       "                        <td id=\"T_d31f1_row5_col7\" class=\"data row5 col7\" >0640</td>\n",
       "                        <td id=\"T_d31f1_row5_col8\" class=\"data row5 col8\" >95.00</td>\n",
       "                        <td id=\"T_d31f1_row5_col9\" class=\"data row5 col9\" >385.00</td>\n",
       "                        <td id=\"T_d31f1_row5_col10\" class=\"data row5 col10\" >3711.00</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d31f1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_d31f1_row6_col0\" class=\"data row6 col0\" >2014-04-01</td>\n",
       "                        <td id=\"T_d31f1_row6_col1\" class=\"data row6 col1\" >19805</td>\n",
       "                        <td id=\"T_d31f1_row6_col2\" class=\"data row6 col2\" >7</td>\n",
       "                        <td id=\"T_d31f1_row6_col3\" class=\"data row6 col3\" >DFW</td>\n",
       "                        <td id=\"T_d31f1_row6_col4\" class=\"data row6 col4\" >OGG</td>\n",
       "                        <td id=\"T_d31f1_row6_col5\" class=\"data row6 col5\" >1410</td>\n",
       "                        <td id=\"T_d31f1_row6_col6\" class=\"data row6 col6\" >125.00</td>\n",
       "                        <td id=\"T_d31f1_row6_col7\" class=\"data row6 col7\" >1743</td>\n",
       "                        <td id=\"T_d31f1_row6_col8\" class=\"data row6 col8\" >138.00</td>\n",
       "                        <td id=\"T_d31f1_row6_col9\" class=\"data row6 col9\" >497.00</td>\n",
       "                        <td id=\"T_d31f1_row6_col10\" class=\"data row6 col10\" >3711.00</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d31f1_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_d31f1_row7_col0\" class=\"data row7 col0\" >2014-04-01</td>\n",
       "                        <td id=\"T_d31f1_row7_col1\" class=\"data row7 col1\" >19805</td>\n",
       "                        <td id=\"T_d31f1_row7_col2\" class=\"data row7 col2\" >8</td>\n",
       "                        <td id=\"T_d31f1_row7_col3\" class=\"data row7 col3\" >HNL</td>\n",
       "                        <td id=\"T_d31f1_row7_col4\" class=\"data row7 col4\" >DFW</td>\n",
       "                        <td id=\"T_d31f1_row7_col5\" class=\"data row7 col5\" >1659</td>\n",
       "                        <td id=\"T_d31f1_row7_col6\" class=\"data row7 col6\" >4.00</td>\n",
       "                        <td id=\"T_d31f1_row7_col7\" class=\"data row7 col7\" >0458</td>\n",
       "                        <td id=\"T_d31f1_row7_col8\" class=\"data row7 col8\" >-22.00</td>\n",
       "                        <td id=\"T_d31f1_row7_col9\" class=\"data row7 col9\" >398.00</td>\n",
       "                        <td id=\"T_d31f1_row7_col10\" class=\"data row7 col10\" >3784.00</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d31f1_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_d31f1_row8_col0\" class=\"data row8 col0\" >2014-04-01</td>\n",
       "                        <td id=\"T_d31f1_row8_col1\" class=\"data row8 col1\" >19805</td>\n",
       "                        <td id=\"T_d31f1_row8_col2\" class=\"data row8 col2\" >9</td>\n",
       "                        <td id=\"T_d31f1_row8_col3\" class=\"data row8 col3\" >JFK</td>\n",
       "                        <td id=\"T_d31f1_row8_col4\" class=\"data row8 col4\" >LAX</td>\n",
       "                        <td id=\"T_d31f1_row8_col5\" class=\"data row8 col5\" >0648</td>\n",
       "                        <td id=\"T_d31f1_row8_col6\" class=\"data row8 col6\" >-7.00</td>\n",
       "                        <td id=\"T_d31f1_row8_col7\" class=\"data row8 col7\" >1029</td>\n",
       "                        <td id=\"T_d31f1_row8_col8\" class=\"data row8 col8\" >19.00</td>\n",
       "                        <td id=\"T_d31f1_row8_col9\" class=\"data row8 col9\" >365.00</td>\n",
       "                        <td id=\"T_d31f1_row8_col10\" class=\"data row8 col10\" >2475.00</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_d31f1_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_d31f1_row9_col0\" class=\"data row9 col0\" >2014-04-01</td>\n",
       "                        <td id=\"T_d31f1_row9_col1\" class=\"data row9 col1\" >19805</td>\n",
       "                        <td id=\"T_d31f1_row9_col2\" class=\"data row9 col2\" >10</td>\n",
       "                        <td id=\"T_d31f1_row9_col3\" class=\"data row9 col3\" >LAX</td>\n",
       "                        <td id=\"T_d31f1_row9_col4\" class=\"data row9 col4\" >JFK</td>\n",
       "                        <td id=\"T_d31f1_row9_col5\" class=\"data row9 col5\" >2156</td>\n",
       "                        <td id=\"T_d31f1_row9_col6\" class=\"data row9 col6\" >21.00</td>\n",
       "                        <td id=\"T_d31f1_row9_col7\" class=\"data row9 col7\" >0556</td>\n",
       "                        <td id=\"T_d31f1_row9_col8\" class=\"data row9 col8\" >1.00</td>\n",
       "                        <td id=\"T_d31f1_row9_col9\" class=\"data row9 col9\" >265.00</td>\n",
       "                        <td id=\"T_d31f1_row9_col10\" class=\"data row9 col10\" >2475.00</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ddd25d9e20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas DataFrame\n",
    "df_pandas = flights.limit(10).toPandas()\n",
    "df_pandas.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('int_date', 'string')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get datatype for data column\n",
    "flights.select(\"date\").dtypes\n",
    "\n",
    "\n",
    "# pandas and spark dataframe's are not exacty the same\n",
    "# Note that DataFrames are immutable, you can create new DataFrame but not modify.\n",
    "import pyspark.sql.functions as F\n",
    "# adding int_date column\n",
    "flights= flights.withColumn(\"int_date\", F.expr(\"replace(date, '-', '')\"))\n",
    "flights.select(\"int_date\").dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('int_date', 'int')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "flights = flights.withColumn(\"int_date\",flights[\"int_date\"].cast(IntegerType()))\n",
    "flights.select(\"int_date\").dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------+------+-----------+---------+---------------+-------+-------------+--------+--------+--------+\n",
      "|      date|airlines|flight_number|origin|destination|departure|departure_delay|arrival|arrival_delay|air_time|distance|int_date|\n",
      "+----------+--------+-------------+------+-----------+---------+---------------+-------+-------------+--------+--------+--------+\n",
      "|2014-04-01|   19805|            1|   JFK|        LAX|     0854|          -6.00|   1217|         2.00|  355.00| 2475.00|20140401|\n",
      "|2014-04-01|   19805|            2|   LAX|        JFK|     0944|          14.00|   1736|       -29.00|  269.00| 2475.00|20140401|\n",
      "|2014-04-01|   19805|            3|   JFK|        LAX|     1224|          -6.00|   1614|        39.00|  371.00| 2475.00|20140401|\n",
      "|2014-04-01|   19805|            4|   LAX|        JFK|     1240|          25.00|   2028|       -27.00|  264.00| 2475.00|20140401|\n",
      "|2014-04-01|   19805|            5|   DFW|        HNL|     1300|          -5.00|   1650|        15.00|  510.00| 3784.00|20140401|\n",
      "+----------+--------+-------------+------+-----------+---------+---------------+-------+-------------+--------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating parquet file for flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------+------+-----------+---------+---------------+-------+-------------+--------+--------+--------+\n",
      "|      date|airlines|flight_number|origin|destination|departure|departure_delay|arrival|arrival_delay|air_time|distance|int_date|\n",
      "+----------+--------+-------------+------+-----------+---------+---------------+-------+-------------+--------+--------+--------+\n",
      "|2014-04-01|   19690|            1|   LAX|        HNL|     0834|          -6.00|   1204|        44.00|  360.00| 2556.00|20140401|\n",
      "|2014-04-01|   19690|            2|   HNL|        LAX|     1342|          -3.00|   2151|       -19.00|  279.00| 2556.00|20140401|\n",
      "|2014-04-01|   19690|            3|   LAX|        HNL|     0952|          -8.00|   1251|        21.00|  339.00| 2556.00|20140401|\n",
      "|2014-04-01|   19690|            4|   HNL|        LAX|     2215|           0.00|   0615|       -20.00|  273.00| 2556.00|20140401|\n",
      "|2014-04-01|   19690|            7|   LAS|        HNL|     0848|         -12.00|   1219|         4.00|  376.00| 2762.00|20140401|\n",
      "|2014-04-01|   19690|            8|   HNL|        LAS|     2226|          -9.00|   0646|       -29.00|  296.00| 2762.00|20140401|\n",
      "|2014-04-01|   19690|           17|   LAS|        HNL|     0147|          -8.00|   0515|        15.00|  377.00| 2762.00|20140401|\n",
      "|2014-04-01|   19690|           18|   HNL|        LAS|     1503|          -2.00|   2327|       -23.00|  299.00| 2762.00|20140401|\n",
      "|2014-04-01|   19690|           19|   SMF|        HNL|     0904|         -11.00|   1205|        15.00|  346.00| 2462.00|20140401|\n",
      "|2014-04-01|   19690|           20|   HNL|        SMF|     1415|          15.00|   2225|        10.00|  276.00| 2462.00|20140401|\n",
      "|2014-04-01|   19690|           21|   SEA|        HNL|     0839|          -6.00|   1150|         0.00|  345.00| 2677.00|20140401|\n",
      "|2014-04-01|   19690|           22|   HNL|        SEA|     1313|          -2.00|   2150|        -5.00|  317.00| 2677.00|20140401|\n",
      "|2014-04-01|   19690|           23|   OAK|        OGG|     0806|         -24.00|   1035|       -15.00|  305.00| 2349.00|20140401|\n",
      "|2014-04-01|   19690|           24|   OGG|        OAK|     1157|          -3.00|   1945|       -20.00|  271.00| 2349.00|20140401|\n",
      "|2014-04-01|   19690|           25|   PDX|        HNL|     1010|          -5.00|   1258|       -17.00|  328.00| 2603.00|20140401|\n",
      "|2014-04-01|   19690|           26|   HNL|        PDX|     1403|           3.00|   2235|         5.00|  309.00| 2603.00|20140401|\n",
      "|2014-04-01|   19690|           29|   SEA|        OGG|     0955|          -5.00|   1252|        -8.00|  339.00| 2640.00|20140401|\n",
      "|2014-04-01|   19690|           30|   OGG|        SEA|     1448|          -7.00|   2324|        -1.00|  320.00| 2640.00|20140401|\n",
      "|2014-04-01|   19690|           35|   PHX|        HNL|     0745|         -15.00|   1201|        26.00|  396.00| 2917.00|20140401|\n",
      "|2014-04-01|   19690|           36|   HNL|        PHX|     1255|          -5.00|   2140|       -20.00|  320.00| 2917.00|20140401|\n",
      "+----------+--------+-------------+------+-----------+---------+---------------+-------+-------------+--------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3591"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_19690_20304 = flights.filter(flights['airlines'].isin([\"19690\", \"20304\"])) \n",
    "flights_19690_20304 = flights_19690_20304.filter(flights_19690_20304['date'].isin([\"2014-04-01\", \"2014-04-02\"]))\n",
    "flights_19690_20304.show()\n",
    "#flights_19690_20304 = flights_19690_20304.drop(\"date\")\n",
    "#flights_19690_20304 = flights_19690_20304.withColumnRenamed(\"date1\",\"date\") \n",
    "\n",
    "flights_19690_20304.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_19690_20304.write.partitionBy(\"airlines\",\"date\",\"flight_number\").mode(\"append\").parquet(\"output/flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- airlines: string (nullable = true)\n",
      " |-- flight_number: string (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- destination: string (nullable = true)\n",
      " |-- departure: string (nullable = true)\n",
      " |-- departure_delay: string (nullable = true)\n",
      " |-- arrival: string (nullable = true)\n",
      " |-- arrival_delay: string (nullable = true)\n",
      " |-- air_time: string (nullable = true)\n",
      " |-- distance: string (nullable = true)\n",
      " |-- int_date: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_19690_20304.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "parqDF=spark.read.parquet(\"output/flights\")\n",
    "parqDF.createOrReplaceTempView(\"ParquetTable\")\n",
    "parkSQL = spark.sql(\"select * from ParquetTable where airlines = '19690' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parkSQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAS,HNL\n",
      "HNL,SMF\n",
      "LAS,HNL\n",
      "LAX,HNL\n",
      "HNL,LAS\n",
      "HNL,LAX\n",
      "OAK,OGG\n",
      "OGG,OAK\n",
      "LAX,HNL\n",
      "PHX,HNL\n",
      "HNL,LAX\n",
      "HNL,SAN\n",
      "HNL,LAS\n",
      "HNL,LAS\n",
      "HNL,LAS\n",
      "SJC,OGG\n",
      "PDX,HNL\n",
      "OAK,OGG\n",
      "HNL,PHX\n",
      "OAK,HNL\n",
      "HNL,PHX\n",
      "HNL,SFO\n",
      "SMF,HNL\n",
      "OGG,SJC\n",
      "OAK,HNL\n",
      "HNL,JFK\n",
      "HNL,LAS\n",
      "HNL,LAX\n",
      "HNL,SFO\n",
      "LAX,HNL\n",
      "PDX,HNL\n",
      "HNL,KOA\n",
      "HNL,SMF\n",
      "ITO,OGG\n",
      "LAS,HNL\n",
      "LAS,HNL\n",
      "HNL,LIH\n",
      "LAX,HNL\n",
      "OGG,HNL\n",
      "OGG,HNL\n",
      "OGG,ITO\n",
      "HNL,LIH\n",
      "OGG,SJC\n",
      "ITO,HNL\n",
      "OGG,SEA\n",
      "LIH,HNL\n",
      "LIH,HNL\n",
      "ITO,OGG\n",
      "HNL,ITO\n",
      "ITO,HNL\n",
      "OGG,ITO\n",
      "HNL,LIH\n",
      "HNL,SEA\n",
      "HNL,PDX\n",
      "SFO,HNL\n",
      "OGG,LIH\n",
      "SEA,OGG\n",
      "KOA,HNL\n",
      "SAN,HNL\n",
      "SJC,OGG\n",
      "PHX,HNL\n",
      "OGG,LIH\n",
      "LIH,HNL\n",
      "OGG,OAK\n",
      "HNL,OGG\n",
      "SEA,HNL\n",
      "HNL,KOA\n",
      "LAX,HNL\n",
      "SFO,HNL\n",
      "LAS,HNL\n",
      "HNL,LAX\n",
      "HNL,LAX\n",
      "LAX,HNL\n",
      "SEA,OGG\n",
      "HNL,LAX\n",
      "OGG,HNL\n",
      "HNL,OGG\n",
      "KOA,HNL\n",
      "KOA,HNL\n",
      "ITO,HNL\n",
      "ITO,OGG\n",
      "HNL,KOA\n",
      "OGG,HNL\n",
      "KOA,HNL\n",
      "HNL,LIH\n",
      "LIH,HNL\n",
      "KOA,HNL\n",
      "ITO,HNL\n",
      "HNL,OGG\n",
      "HNL,OGG\n",
      "OGG,HNL\n",
      "HNL,ITO\n",
      "OGG,ITO\n",
      "LIH,HNL\n",
      "OGG,HNL\n",
      "HNL,OGG\n",
      "ITO,HNL\n",
      "OGG,HNL\n",
      "KOA,HNL\n",
      "HNL,LIH\n",
      "OGG,HNL\n",
      "LIH,HNL\n",
      "OGG,HNL\n",
      "LIH,HNL\n",
      "HNL,OGG\n",
      "ITO,HNL\n",
      "ITO,HNL\n",
      "OGG,HNL\n",
      "HNL,OGG\n",
      "HNL,LIH\n",
      "KOA,HNL\n",
      "HNL,KOA\n",
      "OGG,HNL\n",
      "OGG,HNL\n",
      "HNL,SEA\n",
      "HNL,OAK\n",
      "SMF,HNL\n",
      "OGG,SEA\n",
      "SAN,HNL\n",
      "HNL,SAN\n",
      "SEA,HNL\n",
      "HNL,OAK\n",
      "OGG,HNL\n",
      "LIH,HNL\n",
      "HNL,KOA\n",
      "HNL,OGG\n",
      "OGG,HNL\n",
      "HNL,KOA\n",
      "HNL,OGG\n",
      "KOA,HNL\n",
      "HNL,LIH\n",
      "LIH,HNL\n",
      "LIH,HNL\n",
      "HNL,OGG\n",
      "HNL,ITO\n",
      "LIH,OGG\n",
      "LIH,OGG\n",
      "OGG,HNL\n",
      "HNL,ITO\n",
      "KOA,HNL\n",
      "HNL,KOA\n",
      "HNL,OGG\n",
      "HNL,ITO\n",
      "OGG,HNL\n",
      "HNL,LIH\n",
      "HNL,KOA\n",
      "OGG,HNL\n",
      "HNL,ITO\n",
      "HNL,OGG\n",
      "HNL,ITO\n",
      "LIH,HNL\n",
      "LIH,OGG\n",
      "HNL,LIH\n",
      "OGG,HNL\n",
      "ITO,HNL\n",
      "HNL,LIH\n",
      "HNL,LIH\n",
      "OGG,HNL\n",
      "HNL,OGG\n",
      "LIH,HNL\n",
      "OGG,HNL\n",
      "ITO,HNL\n",
      "OGG,HNL\n",
      "KOA,HNL\n",
      "LIH,HNL\n",
      "KOA,HNL\n",
      "HNL,ITO\n",
      "KOA,OGG\n",
      "LIH,HNL\n",
      "HNL,LIH\n",
      "ITO,HNL\n",
      "HNL,OGG\n",
      "HNL,OGG\n",
      "ITO,HNL\n",
      "HNL,OGG\n",
      "HNL,OGG\n",
      "HNL,OGG\n",
      "HNL,LIH\n",
      "HNL,KOA\n",
      "OGG,HNL\n",
      "LIH,HNL\n",
      "HNL,KOA\n",
      "HNL,KOA\n",
      "HNL,LIH\n",
      "OGG,ITO\n",
      "HNL,LIH\n",
      "LIH,HNL\n",
      "OGG,HNL\n",
      "LIH,HNL\n",
      "HNL,KOA\n",
      "OGG,LIH\n",
      "HNL,KOA\n",
      "LIH,HNL\n",
      "HNL,KOA\n",
      "HNL,KOA\n",
      "HNL,OGG\n",
      "HNL,OGG\n",
      "HNL,ITO\n",
      "HNL,OGG\n",
      "OGG,HNL\n",
      "ITO,HNL\n",
      "ITO,HNL\n",
      "LIH,OGG\n",
      "LIH,HNL\n",
      "LIH,HNL\n",
      "OGG,HNL\n",
      "HNL,LIH\n",
      "HNL,LIH\n",
      "ITO,HNL\n",
      "OGG,HNL\n",
      "KOA,HNL\n",
      "OGG,HNL\n",
      "HNL,KOA\n",
      "OGG,HNL\n",
      "OGG,HNL\n",
      "OGG,HNL\n",
      "HNL,LIH\n",
      "HNL,KOA\n",
      "ITO,HNL\n",
      "LIH,OGG\n",
      "KOA,HNL\n",
      "ITO,OGG\n",
      "HNL,ITO\n",
      "ITO,HNL\n",
      "KOA,HNL\n",
      "HNL,OGG\n",
      "OGG,LIH\n",
      "HNL,OGG\n",
      "HNL,ITO\n",
      "OGG,HNL\n",
      "HNL,OGG\n",
      "LIH,HNL\n",
      "HNL,OGG\n",
      "OGG,HNL\n",
      "HNL,OGG\n",
      "ITO,HNL\n",
      "HNL,OGG\n",
      "KOA,HNL\n",
      "HNL,ITO\n",
      "LIH,HNL\n",
      "LIH,HNL\n",
      "KOA,HNL\n",
      "HNL,KOA\n",
      "HNL,ITO\n",
      "HNL,KOA\n",
      "KOA,HNL\n",
      "KOA,HNL\n",
      "ITO,HNL\n",
      "HNL,KOA\n",
      "HNL,KOA\n",
      "HNL,OGG\n",
      "LIH,OGG\n",
      "HNL,OGG\n",
      "KOA,HNL\n",
      "HNL,LIH\n",
      "OGG,HNL\n",
      "OGG,HNL\n",
      "HNL,ITO\n",
      "HNL,OGG\n",
      "OGG,HNL\n",
      "HNL,ITO\n",
      "HNL,ITO\n",
      "HNL,OGG\n",
      "KOA,HNL\n",
      "OGG,HNL\n",
      "HNL,KOA\n",
      "KOA,HNL\n",
      "HNL,LIH\n",
      "OGG,LIH\n",
      "OGG,HNL\n",
      "HNL,KOA\n",
      "OGG,LIH\n",
      "OGG,HNL\n",
      "HNL,LIH\n",
      "KOA,HNL\n",
      "HNL,OGG\n",
      "HNL,OGG\n",
      "LIH,HNL\n",
      "OGG,HNL\n",
      "HNL,LIH\n",
      "HNL,OGG\n",
      "KOA,HNL\n",
      "KOA,HNL\n",
      "HNL,ITO\n",
      "LIH,HNL\n",
      "HNL,KOA\n",
      "HNL,OGG\n",
      "LIH,OGG\n",
      "OGG,HNL\n",
      "HNL,OGG\n",
      "HNL,OGG\n",
      "LIH,HNL\n",
      "LIH,HNL\n",
      "HNL,LIH\n",
      "HNL,KOA\n",
      "OGG,HNL\n",
      "HNL,OGG\n",
      "ITO,HNL\n",
      "OGG,HNL\n",
      "OGG,HNL\n",
      "HNL,KOA\n",
      "KOA,HNL\n",
      "ITO,HNL\n",
      "KOA,HNL\n",
      "ITO,HNL\n",
      "HNL,OGG\n",
      "HNL,OGG\n",
      "ITO,HNL\n",
      "OGG,HNL\n",
      "HNL,OGG\n",
      "HNL,OGG\n",
      "HNL,KOA\n",
      "HNL,OGG\n",
      "OGG,HNL\n",
      "ITO,HNL\n",
      "HNL,KOA\n",
      "HNL,ITO\n",
      "KOA,HNL\n",
      "OGG,LIH\n",
      "OGG,HNL\n",
      "HNL,PDX\n",
      "OGG,KOA\n",
      "KOA,OGG\n",
      "KOA,OGG\n",
      "KOA,OGG\n",
      "OGG,KOA\n",
      "OGG,KOA\n",
      "HNL,LIH\n",
      "HNL,ITO\n",
      "ITO,HNL\n",
      "OGG,HNL\n",
      "KOA,HNL\n",
      "HNL,KOA\n",
      "HNL,ITO\n",
      "HNL,LIH\n",
      "HNL,KOA\n",
      "HNL,OGG\n",
      "LIH,HNL\n",
      "OGG,HNL\n",
      "HNL,ITO\n",
      "ITO,HNL\n",
      "HNL,OGG\n",
      "HNL,OGG\n",
      "HNL,ITO\n",
      "HNL,ITO\n",
      "KOA,HNL\n",
      "HNL,LIH\n",
      "OGG,HNL\n",
      "LIH,OGG\n",
      "HNL,LIH\n",
      "OGG,LIH\n",
      "HNL,ITO\n",
      "OGG,HNL\n",
      "HNL,LIH\n",
      "LIH,HNL\n",
      "HNL,LIH\n",
      "HNL,OGG\n",
      "HNL,ITO\n",
      "KOA,HNL\n",
      "KOA,HNL\n",
      "HNL,ITO\n",
      "LIH,HNL\n",
      "HNL,OGG\n",
      "LIH,HNL\n",
      "ITO,HNL\n",
      "HNL,OGG\n",
      "LIH,HNL\n",
      "OGG,HNL\n",
      "OGG,KOA\n",
      "ITO,HNL\n",
      "HNL,KOA\n",
      "ITO,HNL\n",
      "HNL,KOA\n",
      "HNL,LIH\n",
      "HNL,LIH\n",
      "HNL,OGG\n",
      "KOA,HNL\n",
      "HNL,KOA\n",
      "HNL,ITO\n",
      "HNL,OGG\n",
      "HNL,ITO\n",
      "HNL,OGG\n",
      "OGG,HNL\n",
      "KOA,HNL\n",
      "HNL,LIH\n",
      "HNL,LAS\n",
      "SMF,HNL\n",
      "HNL,LAS\n",
      "HNL,LAX\n",
      "LAX,HNL\n",
      "LAS,HNL\n",
      "HNL,SMF\n",
      "LAX,HNL\n",
      "HNL,LAX\n",
      "LAS,HNL\n"
     ]
    }
   ],
   "source": [
    "# Collect the data to Python List\n",
    "dataCollect = parkSQL.collect()\n",
    "for row in dataCollect:\n",
    "    print(row['origin'] + \",\" +row['destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------+------+-----------+---------+---------------+-------+-------------+--------+--------+--------+\n",
      "|      date|airlines|flight_number|origin|destination|departure|departure_delay|arrival|arrival_delay|air_time|distance|int_date|\n",
      "+----------+--------+-------------+------+-----------+---------+---------------+-------+-------------+--------+--------+--------+\n",
      "|2014-04-01|   19805|            1|   JFK|        LAX|     0854|          -6.00|   1217|         2.00|  355.00| 2475.00|20140401|\n",
      "|2014-04-01|   19805|            2|   LAX|        JFK|     0944|          14.00|   1736|       -29.00|  269.00| 2475.00|20140401|\n",
      "|2014-04-01|   19805|            3|   JFK|        LAX|     1224|          -6.00|   1614|        39.00|  371.00| 2475.00|20140401|\n",
      "|2014-04-01|   19805|            4|   LAX|        JFK|     1240|          25.00|   2028|       -27.00|  264.00| 2475.00|20140401|\n",
      "|2014-04-01|   19805|            5|   DFW|        HNL|     1300|          -5.00|   1650|        15.00|  510.00| 3784.00|20140401|\n",
      "|2014-04-01|   19805|            6|   OGG|        DFW|     1901|         126.00|   0640|        95.00|  385.00| 3711.00|20140401|\n",
      "|2014-04-01|   19805|            7|   DFW|        OGG|     1410|         125.00|   1743|       138.00|  497.00| 3711.00|20140401|\n",
      "|2014-04-01|   19805|            8|   HNL|        DFW|     1659|           4.00|   0458|       -22.00|  398.00| 3784.00|20140401|\n",
      "|2014-04-01|   19805|            9|   JFK|        LAX|     0648|          -7.00|   1029|        19.00|  365.00| 2475.00|20140401|\n",
      "|2014-04-01|   19805|           10|   LAX|        JFK|     2156|          21.00|   0556|         1.00|  265.00| 2475.00|20140401|\n",
      "|2014-04-01|   19805|           12|   LAX|        JFK|     1113|          -2.00|   1910|       -40.00|  267.00| 2475.00|20140401|\n",
      "|2014-04-01|   19805|           14|   OGG|        LAX|     2235|           5.00|   0618|       -17.00|  270.00| 2486.00|20140401|\n",
      "|2014-04-01|   19805|           15|   BOS|        ORD|     0611|          -9.00|   0756|       -19.00|  129.00|  867.00|20140401|\n",
      "|2014-04-01|   19805|           16|   SFO|        JFK|     1312|          17.00|   2107|       -33.00|  268.00| 2586.00|20140401|\n",
      "|2014-04-01|   19805|           17|   ATL|        MIA|     0630|          -5.00|   0813|       -17.00|   83.00|  594.00|20140401|\n",
      "|2014-04-01|   19805|           18|   SFO|        JFK|     0022|         112.00|   0833|        88.00|  288.00| 2586.00|20140401|\n",
      "|2014-04-01|   19805|           19|   JFK|        LAX|     1024|          -6.00|   1353|        18.00|  359.00| 2475.00|20140401|\n",
      "|2014-04-01|   19805|           20|   SFO|        JFK|     1715|         135.00|   0130|       120.00|  277.00| 2586.00|20140401|\n",
      "|2014-04-01|   19805|           21|   JFK|        LAX|     1906|          -4.00|   2246|        16.00|  359.00| 2475.00|20140401|\n",
      "|2014-04-01|   19805|           22|   LAX|        JFK|     1458|          -2.00|   2336|        11.00|  272.00| 2475.00|20140401|\n",
      "+----------+--------+-------------+------+-----------+---------+---------------+-------+-------------+--------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights.count()\n",
    "flights.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a flights table - sql table , The lifetime of this temporary table is tied  to the SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'airlines',\n",
       " 'flight_number',\n",
       " 'origin',\n",
       " 'destination',\n",
       " 'departure',\n",
       " 'departure_delay',\n",
       " 'arrival',\n",
       " 'arrival_delay',\n",
       " 'air_time',\n",
       " 'distance',\n",
       " 'int_date']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "createOrReplaceTempView creates (or replaces if that view name already exists) a lazily evaluated \"view\" \n",
    "that you can then use like a hive table in Spark SQL. It does not persist to memory unless you cache or persist the \n",
    "dataset that underpins the view.\n",
    "'''\n",
    "flights.createOrReplaceTempView(\"flights\")\n",
    "flights.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_count = spark.sql(\"SELECT COUNT(*) FROM flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[count(1): bigint]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476881"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_count.collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframes created using SQL commands can be aggregated, grouped etc. exactly as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_distance_df = spark.sql(\"SELECT distance FROM flights\")\\\n",
    "                         .agg({\"distance\":\"sum\"})\\\n",
    "                         .withColumnRenamed(\"sum(distance)\",\"total_distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching\n",
    "Spark will read the Parquet, csv, etc, execute the query only once and then cache it. Then the code in the loop will use the cached, pre-calculated DataFrame. Imagine that you are working with a lot of data, and you run a series of queries and actions on it without using caching. It runs again and again without you even noticing. This can add hours to the job running time or even make the job fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[total_distance: double]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_distance_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|total_distance|\n",
      "+--------------+\n",
      "|  3.79052917E8|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_distance_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain Plan/Query Execution Plan\n",
    "The best way to make sure everything has run as expected is to look at the execution plan.\n",
    "You can see in the following execution plan the key words InMemoryTableScan and InMemoryRelation\n",
    "which indicate that we are working on a cached DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) ColumnarToRow\n",
      "+- InMemoryTableScan [total_distance#486]\n",
      "      +- InMemoryRelation [total_distance#486], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- *(2) HashAggregate(keys=[], functions=[sum(cast(distance#26 as double))])\n",
      "               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#228]\n",
      "                  +- *(1) HashAggregate(keys=[], functions=[partial_sum(cast(distance#26 as double))])\n",
      "                     +- FileScan csv [distance#26] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/padma/github/sparksql-awsglue/aws-glue/datasets/flights.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<distance:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_distance_df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing flight delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|year|\n",
      "+----+\n",
      "|2014|\n",
      "+----+\n",
      "\n",
      "+----------+--------+-------------+---------------+\n",
      "|      date|airlines|flight_number|departure_delay|\n",
      "+----------+--------+-------------+---------------+\n",
      "|2014-04-01|   19805|            1|          -6.00|\n",
      "|2014-04-01|   19805|            2|          14.00|\n",
      "|2014-04-01|   19805|            3|          -6.00|\n",
      "|2014-04-01|   19805|            4|          25.00|\n",
      "|2014-04-01|   19805|            5|          -5.00|\n",
      "|2014-04-01|   19805|            6|         126.00|\n",
      "|2014-04-01|   19805|            7|         125.00|\n",
      "|2014-04-01|   19805|            8|           4.00|\n",
      "|2014-04-01|   19805|            9|          -7.00|\n",
      "|2014-04-01|   19805|           10|          21.00|\n",
      "|2014-04-01|   19805|           12|          -2.00|\n",
      "|2014-04-01|   19805|           14|           5.00|\n",
      "|2014-04-01|   19805|           15|          -9.00|\n",
      "|2014-04-01|   19805|           16|          17.00|\n",
      "|2014-04-01|   19805|           17|          -5.00|\n",
      "|2014-04-01|   19805|           18|         112.00|\n",
      "|2014-04-01|   19805|           19|          -6.00|\n",
      "|2014-04-01|   19805|           20|         135.00|\n",
      "|2014-04-01|   19805|           21|          -4.00|\n",
      "|2014-04-01|   19805|           22|          -2.00|\n",
      "+----------+--------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distinct_year = spark.sql(\n",
    "    \"SELECT distinct year(date) year  \" +\n",
    "    \"FROM flights\")\n",
    "distinct_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_delays_2014 = spark.sql(\n",
    "    \"SELECT date, airlines, flight_number, departure_delay \" +\n",
    "    \"FROM flights WHERE departure_delay > 0 and year(date) = 2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------+---------------+\n",
      "|      date|airlines|flight_number|departure_delay|\n",
      "+----------+--------+-------------+---------------+\n",
      "|2014-04-01|   19805|            2|          14.00|\n",
      "|2014-04-01|   19805|            4|          25.00|\n",
      "|2014-04-01|   19805|            6|         126.00|\n",
      "|2014-04-01|   19805|            7|         125.00|\n",
      "|2014-04-01|   19805|            8|           4.00|\n",
      "+----------+--------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_delays_2014.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------+---------------+\n",
      "|      date|airlines|flight_number|departure_delay|\n",
      "+----------+--------+-------------+---------------+\n",
      "|2014-04-27|   20366|         5246|          99.00|\n",
      "|2014-04-27|   19393|         2948|          99.00|\n",
      "|2014-04-27|   20366|         5365|          99.00|\n",
      "|2014-04-26|   19977|          616|          99.00|\n",
      "|2014-04-27|   20366|         6030|          99.00|\n",
      "+----------+--------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_delays_2014.orderBy(all_delays_2014.departure_delay.desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total number of delayed flights in 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_delays_2014.createOrReplaceTempView(\"all_delays_2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_count = spark.sql(\"SELECT COUNT(departure_delay) FROM all_delays_2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|count(departure_delay)|\n",
      "+----------------------+\n",
      "|                179015|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179015"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_count.collect()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage of flights delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.53871510922012"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_percent = delay_count.collect()[0][0] / flights_count.collect()[0][0] * 100\n",
    "delay_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding delay per aIrlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Code', 'Description']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines = spark.read\\\n",
    "                .format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .load(airlinesPath)\n",
    "airlines.createOrReplaceTempView(\"airlines\")\n",
    "airlines = spark.sql(\"SELECT * FROM airlines\")\n",
    "airlines.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_per_airline = spark.sql(\"SELECT airlines, departure_delay FROM flights\")\\\n",
    "                         .groupBy(\"airlines\")\\\n",
    "                         .agg({\"departure_delay\":\"avg\"})\\\n",
    "                         .withColumnRenamed(\"avg(departure_delay)\", \"departure_delay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|airlines|   departure_delay|\n",
      "+--------+------------------+\n",
      "|   19393|13.429567657134724|\n",
      "|   20366|12.296210112379818|\n",
      "|   19977| 8.818392620527979|\n",
      "|   20436| 8.716275167785234|\n",
      "|   20409|  8.31110357194785|\n",
      "+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_per_airline.orderBy(delay_per_airline.departure_delay.desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_per_airline.createOrReplaceTempView(\"delay_per_airline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_per_airline = spark.sql(\"SELECT * FROM delay_per_airline ORDER BY departure_delay DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|airlines|   departure_delay|\n",
      "+--------+------------------+\n",
      "|   19393|13.429567657134724|\n",
      "|   20366|12.296210112379818|\n",
      "|   19977| 8.818392620527979|\n",
      "|   20436| 8.716275167785234|\n",
      "|   20409|  8.31110357194785|\n",
      "+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_per_airline.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL join operations \n",
    "\n",
    "* Get the names of the delayed flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+-----+--------------------+\n",
      "|airlines|   departure_delay| Code|         Description|\n",
      "+--------+------------------+-----+--------------------+\n",
      "|   19393|13.429567657134724|19393|Southwest Airline...|\n",
      "|   20366|12.296210112379818|20366|ExpressJet Airlin...|\n",
      "|   19977| 8.818392620527979|19977|United Air Lines ...|\n",
      "|   20436| 8.716275167785234|20436|Frontier Airlines...|\n",
      "|   20409|  8.31110357194785|20409| JetBlue Airways: B6|\n",
      "+--------+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_per_airline = spark.sql(\"SELECT * FROM delay_per_airline \" +\n",
    "                              \"JOIN airlines ON airlines.code = delay_per_airline.airlines \" +\n",
    "                              \"ORDER BY departure_delay DESC\")\n",
    "\n",
    "delay_per_airline.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+--------------------+\n",
      "|airlines|   departure_delay|         Description|\n",
      "+--------+------------------+--------------------+\n",
      "|   19393|13.429567657134724|Southwest Airline...|\n",
      "|   20366|12.296210112379818|ExpressJet Airlin...|\n",
      "|   19977| 8.818392620527979|United Air Lines ...|\n",
      "|   20436| 8.716275167785234|Frontier Airlines...|\n",
      "|   20409|  8.31110357194785| JetBlue Airways: B6|\n",
      "+--------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_per_airline.drop(\"code\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
